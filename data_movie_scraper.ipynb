{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a50075ad",
      "metadata": {
        "id": "a50075ad"
      },
      "source": [
        "IMDb Movie Scraper\n",
        "Author: **Michael Saulon B (MSB46)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9123857",
      "metadata": {
        "id": "f9123857"
      },
      "source": [
        "Objective:\n",
        "\n",
        "The purpose of this notebook is to scrape various information from the most popular and top rated animated movies according to IMDb. Upon scraping the data, I will be able to convert that data into a more readable format through a DataFrame which will be cleaned and modeled upon later.\n",
        "\n",
        "**_Note: The scrapers used were for educational purposes only._**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e98f4f9",
      "metadata": {
        "id": "4e98f4f9"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.wait import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from selenium.common.exceptions import TimeoutException\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from tkinter import filedialog\n",
        "from tkinter import Tk\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3bf84a7",
      "metadata": {
        "scrolled": true,
        "id": "e3bf84a7"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "links = []\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_extension('/content/selenium_extension/ublock.crx')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9fde56f",
      "metadata": {
        "id": "f9fde56f"
      },
      "source": [
        "#### Approach\n",
        "The first step would be to gather all of the links that lead to the IMDb page of each animated movie. Since the last time I extracted movie data, the layout of the IMDb changed drastically which meant that I have to make changes to the selectors used to find the elements that had the data I needed. This was especially the case for the page that lists movies in a top-down layout. Instead of using a third-party API like I previously did, I used Selenium to extract the IMdb links to every movie page. Selenium was also useful for scrolling down and automatically clicking \"Show 50 more\" on the bottom of the page to get as many links as possible.\n",
        "\n",
        "Previously, I used Selenium's web driver within a movie's page search for a movie's specifics. However, I decided to use BeautifulSoup this time as the issue with Selenium is that the time it takes to load a page is too volatile which can some elements to sometimes not be found. BS4 is also much quicker in returning content which means less waiting times.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9552bf",
      "metadata": {
        "id": "cb9552bf"
      },
      "outputs": [],
      "source": [
        "# Get links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7d887dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "d7d887dc",
        "outputId": "ef46f176-a6e6-42a9-e603-e48f85e73d8c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SessionNotCreatedException",
          "evalue": "Message: session not created: Chrome failed to start: exited normally.\n  (session not created: DevToolsActivePort file doesn't exist)\n  (The process started from chrome location /root/.cache/selenium/chrome/linux64/120.0.6099.109/chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\nStacktrace:\n#0 0x56158ea5df83 <unknown>\n#1 0x56158e716cf7 <unknown>\n#2 0x56158e74e60e <unknown>\n#3 0x56158e74b26e <unknown>\n#4 0x56158e79b80c <unknown>\n#5 0x56158e78fe53 <unknown>\n#6 0x56158e757dd4 <unknown>\n#7 0x56158e7591de <unknown>\n#8 0x56158ea22531 <unknown>\n#9 0x56158ea26455 <unknown>\n#10 0x56158ea0ef55 <unknown>\n#11 0x56158ea270ef <unknown>\n#12 0x56158e9f299f <unknown>\n#13 0x56158ea4b008 <unknown>\n#14 0x56158ea4b1d7 <unknown>\n#15 0x56158ea5d124 <unknown>\n#16 0x7f75d17e3ac3 <unknown>\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-3b8b1b9400dd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/links.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"links.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.imdb.com/search/title/?title_type=feature&num_votes=5000,&genres=animation&sort=alpha,asc&view=advanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mbrowser_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDesiredCapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHROME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mvendor_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"goog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authenticator_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sessionId\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"capabilities\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mSessionNotCreatedException\u001b[0m: Message: session not created: Chrome failed to start: exited normally.\n  (session not created: DevToolsActivePort file doesn't exist)\n  (The process started from chrome location /root/.cache/selenium/chrome/linux64/120.0.6099.109/chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\nStacktrace:\n#0 0x56158ea5df83 <unknown>\n#1 0x56158e716cf7 <unknown>\n#2 0x56158e74e60e <unknown>\n#3 0x56158e74b26e <unknown>\n#4 0x56158e79b80c <unknown>\n#5 0x56158e78fe53 <unknown>\n#6 0x56158e757dd4 <unknown>\n#7 0x56158e7591de <unknown>\n#8 0x56158ea22531 <unknown>\n#9 0x56158ea26455 <unknown>\n#10 0x56158ea0ef55 <unknown>\n#11 0x56158ea270ef <unknown>\n#12 0x56158e9f299f <unknown>\n#13 0x56158ea4b008 <unknown>\n#14 0x56158ea4b1d7 <unknown>\n#15 0x56158ea5d124 <unknown>\n#16 0x7f75d17e3ac3 <unknown>\n"
          ]
        }
      ],
      "source": [
        "if not(os.path.isfile(\"/content/links.txt\")):\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    with open(\"links.txt\", \"w\") as l:\n",
        "        driver.get('https://www.imdb.com/search/title/?title_type=feature&num_votes=5000,&genres=animation&sort=alpha,asc&view=advanced')\n",
        "        while True:\n",
        "            try:\n",
        "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
        "                btn_show_more = WebDriverWait(driver, 6).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\".ipc-see-more__text\")))\n",
        "                driver.execute_script(\"arguments[0].click()\",btn_show_more)\n",
        "\n",
        "            except TimeoutException:\n",
        "                selector = '/html/body/div[2]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li/div[1]/div/div/div[1]/div[2]/div[1]/a'\n",
        "                movie_we = driver.find_elements(By.XPATH, selector)\n",
        "                print(f\"Found items: {len(movie_we)}\")\n",
        "\n",
        "                for i in range(len(movie_we)):\n",
        "                        href = movie_we[i].get_attribute('href')\n",
        "                        links.append(href)\n",
        "                        l.write(str(href) +\"\\n\")\n",
        "                        # print(href)\n",
        "                driver.close()\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95210e13",
      "metadata": {
        "id": "95210e13"
      },
      "outputs": [],
      "source": [
        "# r.status_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b052f092",
      "metadata": {
        "id": "b052f092"
      },
      "outputs": [],
      "source": [
        "# j = json.loads(r.text)\n",
        "# df = pd.DataFrame(j['movie'])\n",
        "df_columns = [\n",
        "    \"title\",\n",
        "    \"year\",\n",
        "    \"rating\",\n",
        "    \"runtime\",\n",
        "    \"votes\",\n",
        "    \"votescore\",\n",
        "    \"metacritic\",\n",
        "    \"budget\",\n",
        "    \"opening_na\",\n",
        "    \"worldwide\",\n",
        "    \"story\",\n",
        "    \"genres\",\n",
        "    \"origin\",\n",
        "    \"languages\",\n",
        "    \"companies\",\n",
        "    \"release_date\",\n",
        "    \"cast\",\n",
        "    \"crew_count\"\n",
        "    \"writers\",\n",
        "    \"director\",\n",
        "]\n",
        "df = pd.DataFrame(columns=df_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a467c29",
      "metadata": {
        "id": "4a467c29"
      },
      "source": [
        "### Some more hurdles to overcome\n",
        "While most pages are consistent in their layout, some pages tend to be structured differently meaning copying the CSS selector path of an element isn't going to cut it alone. As a solution I noticed that most elements I pick data from have a parent element with the attribute \"test-dataid\" which conviniently has a distinct name like \"title-boxoffice-budget\" or \"genres\" which makes things a lot easier to extract.\n",
        "\n",
        "I originally wanted to use a page's 'story line' section to extract things like the rating and tagline of a movie. But when using an html parser to extract the html content of a page, some sections aren't to be seen. My assumption is that certain sections like the storyline section and possibly others aren't loaded/included until someone or something physically accesses the web page. Whether or not I find a workaround is yet to be determined.\n",
        "\n",
        "As of now I found an alternate way to collect the genres, story description, and rating of a movie without using the storyline section as a selector. Unfortunately, I wasn't able to find a way for extracting a movie's tagline (if it has one). Luckily, it's probably one of the less important things to extract from a movie in my perspective so no big deal in the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c37a92e6",
      "metadata": {
        "id": "c37a92e6"
      },
      "outputs": [],
      "source": [
        "def separated_by_commas(l):\n",
        "    return \", \".join(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dcaa668",
      "metadata": {
        "id": "2dcaa668"
      },
      "outputs": [],
      "source": [
        "def read_random(file):\n",
        "    lines = file.read().splitlines()\n",
        "    return random.choice(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa0b20c",
      "metadata": {
        "id": "cfa0b20c"
      },
      "outputs": [],
      "source": [
        "x = 0\n",
        "with open(\"links.txt\") as file:\n",
        "    for link in file:\n",
        "        links.append(link)\n",
        "    for link in tqdm(links, desc=\"Getting movie data...\"):\n",
        "        try:\n",
        "            r = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    #         print(r)\n",
        "            content = r.text\n",
        "            soup = BeautifulSoup(content, \"html.parser\")\n",
        "    #         print(soup.prettify())\n",
        "\n",
        "            # Title, Year\n",
        "            title = soup.select_one(\"h1[data-testid='hero__pageTitle'] > span\").get_text()\n",
        "            year = soup.select_one(\"div.sc-e226b0e3-3.dwkouE > div.sc-69e49b85-0.jqlHBQ > ul > li:nth-child(1)\").get_text()\n",
        "            print(title, year)\n",
        "\n",
        "            # Rating, Runtime\n",
        "            runtime = soup.select_one(\"li[data-testid='title-techspec_runtime'] > div\").get_text()\n",
        "\n",
        "            # The order of details underneath each page's title is as follows: Year, Rating, Runtime\n",
        "            # Sometimes rating isn't present and instead lists the year and runtime only.\n",
        "            # If there is only two items underneath, I will assume that the film has no rating.\n",
        "            if len(soup.select(\".sc-d8941411-2 > li\")) < 3:\n",
        "                rating = \"Not Rated\"\n",
        "            else:\n",
        "                rating = soup.select_one(\"div.sc-e226b0e3-3.dwkouE > div.sc-69e49b85-0.jqlHBQ > ul > li:nth-child(2)\").get_text()\n",
        "    #         rating = soup.select_one(\"section[data-testid='Storyline']\").get_text()\n",
        "\n",
        "            print(runtime, rating)\n",
        "\n",
        "            # Votes, Votescore, Metacritic\n",
        "            votes = soup.select_one(\"div.sc-bde20123-0.dLwiNw > div.sc-bde20123-3.gPVQxL\").get_text()\n",
        "            votescore = soup.select_one(\"div.sc-bde20123-0.dLwiNw > div.sc-bde20123-2.cdQqzc > span.sc-bde20123-1.cMEQkK\").get_text()\n",
        "            metacritic = soup.select_one(\".sc-b0901df4-0\")\n",
        "            if metacritic:\n",
        "                metacritic = metacritic.get_text() if metacritic else \"\"\n",
        "\n",
        "            print(votes,votescore, metacritic)\n",
        "\n",
        "            # Director, Writers\n",
        "            directors_elmt = soup.select(\"div.sc-69e49b85-3.dIOekc > div > ul > li:nth-child(1) > div > ul > li\")\n",
        "            directors = separated_by_commas([d.get_text() for d in directors_elmt])\n",
        "            writers_elmt = soup.select(\"div.sc-69e49b85-3.dIOekc > div > ul > li:nth-child(2) > div > ul > li\")\n",
        "            writers = separated_by_commas([w.get_text() for w in writers_elmt])\n",
        "\n",
        "            print(directors)\n",
        "            print(writers)\n",
        "\n",
        "\n",
        "            # Genre\n",
        "            genres_elmt = soup.select(\"div[data-testid='genres'] > div > a > span\")\n",
        "    #         genres_elmt = soup.select('li[@data-testid=\"storyline-genres\"] > div > ul > li')\n",
        "            genres = separated_by_commas([g.get_text() for g in genres_elmt])\n",
        "            print(genres)\n",
        "\n",
        "    #     \"budget_est\",\"opening_weekend\", worldwide_gross\"\n",
        "            budget = soup.select_one(\"li[data-testid='title-boxoffice-budget'] > div\")\n",
        "            budget = budget.get_text() if budget else \"\"\n",
        "\n",
        "            opening_na = soup.select_one(\"li[data-testid='title-boxoffice-openingweekenddomestic'] > div > ul > li\")\n",
        "            opening_na = opening_na.get_text() if opening_na else \"\"\n",
        "\n",
        "            worldwide = soup.select_one(\"li[data-testid='title-boxoffice-cumulativeworldwidegross'] > div\")\n",
        "            worldwide = worldwide.get_text() if worldwide else \"\"\n",
        "\n",
        "            print(worldwide, budget)\n",
        "\n",
        "            # Release date, Country/Origin, Languages\n",
        "            releasedate = soup.select_one(\"li[data-testid='title-details-releasedate'] > div\").get_text()\n",
        "            origin_elmt = soup.select(\"li[data-testid='title-details-origin'] > div > ul > li\")\n",
        "            if origin_elmt:\n",
        "                origin = separated_by_commas([c.get_text() for c in origin_elmt])\n",
        "\n",
        "            lang_elmt = soup.select(\"li[data-testid='title-details-languages'] > div > ul > li\")\n",
        "            language = separated_by_commas([l.get_text() for l in lang_elmt]) if lang_elmt else \"\"\n",
        "            print(releasedate, origin, language)\n",
        "\n",
        "            # Companies\n",
        "\n",
        "            company_elmt = soup.select(\"li[data-testid='title-details-companies'] > div > ul > li\")\n",
        "            company = separated_by_commas([c.get_text() for c in company_elmt]) if company_elmt else \"\"\n",
        "            print(company)\n",
        "\n",
        "            # Story\n",
        "\n",
        "            story = soup.select_one(\"p[data-testid='plot'] > span.sc-466bb6c-2\").get_text()\n",
        "            print(story)\n",
        "\n",
        "\n",
        "            #\n",
        "            # Cast\n",
        "            r = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "            content = r.text\n",
        "            soup = BeautifulSoup(content, \"html.parser\")\n",
        "\n",
        "            cast_elmt = soup.select(\"table.cast_list > tbody > tr> td:nth-child(2) > a\")\n",
        "            cast = separated_by_commas([a.get_text() for a in cast_elmt])\n",
        "\n",
        "            crew_elmt = soup.select(\"tbody > tr > td.name > a\")\n",
        "            crew_count = len(list(set(crew_elmt)))\n",
        "\n",
        "            print(cast)\n",
        "            print(crew_count)\n",
        "\n",
        "            values = [title, year, rating, runtime, votes, votescore,\n",
        "                      metacritic, budget, opening_na, worldwide, story,\n",
        "                      genres, origin, language, company, releasedate,\n",
        "                      cast, crew_count, writers, directors]\n",
        "\n",
        "            df.loc[x] = values\n",
        "\n",
        "            x += 1\n",
        "            # Year\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Index {x}\\n{e}\")\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3299ee9a",
      "metadata": {
        "id": "3299ee9a"
      },
      "outputs": [],
      "source": [
        "len(links)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98603823",
      "metadata": {
        "id": "98603823"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f8c6df",
      "metadata": {
        "id": "28f8c6df"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"imdb_animated_movies.csv\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4801366",
      "metadata": {
        "id": "e4801366"
      },
      "source": [
        "After converting this table into a readable csv, the data scraping process is concluded. Next step involves cleaning the data using the recently made csv file as a base."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}